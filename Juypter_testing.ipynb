{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.environ.get(\"OPEN_AI_ENDPOINT\"),\n",
    "    api_key=os.environ.get(\"OPEN_AI_KEY\"),\n",
    "    api_version=\"2023-05-15\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_id = os.environ.get(\"OPEN_AI_DEPLOYMENT_NAME\")\n",
    "\n",
    "# This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\n",
    "speech_config = speechsdk.SpeechConfig(\n",
    "    subscription=os.environ.get(\"SPEECH_KEY\"), region=os.environ.get(\"SPEECH_REGION\")\n",
    ")\n",
    "audio_output_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "\n",
    "# Should be the locale for the speaker's language.\n",
    "speech_config.speech_recognition_language = \"en-US\"\n",
    "speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "    speech_config=speech_config, audio_config=audio_config\n",
    ")\n",
    "\n",
    "# The language of the voice that responds on behalf of Azure OpenAI.\n",
    "speech_config.speech_synthesis_voice_name = \"en-US-JennyMultilingualNeural\"\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(\n",
    "    speech_config=speech_config, audio_config=audio_output_config\n",
    ")\n",
    "# tts sentence end mark\n",
    "tts_sentence_end = [\".\", \"!\", \"?\", \";\", \"。\", \"！\", \"？\", \"；\", \"\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_test(prompt):\n",
    "    return client.chat.completions.create(model=deployment_id, max_tokens=200, stream=True, messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_openai(prompt):\n",
    "    # Ask Azure OpenAI in streaming way\n",
    "    response = response_test(prompt)\n",
    "    collected_messages = []\n",
    "    last_tts_request = None\n",
    "\n",
    "    # iterate through the stream response stream\n",
    "    for chunk in response:\n",
    "        if len(chunk.choices) > 0:\n",
    "            chunk_message = chunk.choices[0].delta.content  # extract the message\n",
    "            if chunk_message is not None:\n",
    "                collected_messages.append(chunk_message)  # save the message\n",
    "                if chunk_message in tts_sentence_end: # sentence end found\n",
    "                    text = ''.join(collected_messages).strip() # join the recieved message together to build a sentence\n",
    "                    if text != '': # if sentence only have \\n or space, we could skip\n",
    "                        print(f\"Speech synthesized to speaker for: {text}\")\n",
    "                        last_tts_request = speech_synthesizer.speak_text_async(text)\n",
    "                        collected_messages.clear()\n",
    "    if last_tts_request:\n",
    "        last_tts_request.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuously listens for speech input to recognize and send as text to Azure OpenAI\n",
    "def chat_with_open_ai():\n",
    "    while True:\n",
    "        print(\"Azure OpenAI is listening. Say 'Stop' or press Ctrl-Z to end the conversation.\")\n",
    "        try:\n",
    "            # Get audio from the microphone and then send it to the TTS service.\n",
    "            speech_recognition_result = speech_recognizer.recognize_once_async().get()\n",
    "\n",
    "            # If speech is recognized, send it to Azure OpenAI and listen for the response.\n",
    "            if speech_recognition_result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "                if speech_recognition_result.text == \"Stop.\": \n",
    "                    print(\"Conversation ended.\")\n",
    "                    break\n",
    "                print(\"Recognized speech: {}\".format(speech_recognition_result.text))\n",
    "                ask_openai(speech_recognition_result.text)\n",
    "            elif speech_recognition_result.reason == speechsdk.ResultReason.NoMatch:\n",
    "                print(\"No speech could be recognized: {}\".format(speech_recognition_result.no_match_details))\n",
    "                break\n",
    "            elif speech_recognition_result.reason == speechsdk.ResultReason.Canceled:\n",
    "                cancellation_details = speech_recognition_result.cancellation_details\n",
    "                print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "                if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "                    print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     chat_with_open_ai()\n",
    "# except Exception as err:\n",
    "#     print(\"Encountered exception. {}\".format(err))\n",
    "\n",
    "chat_with_open_ai()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
